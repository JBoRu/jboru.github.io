<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html manifest="welcome.manifest">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <meta content="yes" name="apple-mobile-web-app-capable">
    <meta content="black" name="apple-mobile-web-app-status-bar-style">
    <meta content="telephone=no" name="format-detection">
    <meta name="author" content="Junyi Li">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        
        a {
            color: #07889b;
            /*#1772d0;*/
            text-decoration: none;
        }
        
        a:focus,
        a:hover {
            color: #e37222;
            /*#f7b733;*/
            /*f09228;*/
            text-decoration: none;
        }
        
        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 15px;
            /*14*/
        }
        
        strong {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 15px;
            /*14*/
        }
        
        heading {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 22px;
            color: #e37222;
            /*#fc4a1a;*/
        }
        
        heading2 {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 18px;
        }
        
        papertitle {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 15px;
            /*14*/
            font-weight: 700;
        }
        
        name {
            font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif;
            /*'Lato', Verdana, Helvetica, sans-serif;*/
            font-size: 42px;
        }
        
        li:not(:last-child) {
            margin-bottom: 5px;
        }
        
        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }
        
        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        span.highlight {
            background-color: #ffffd0;
        }
    </style>
    <link href="https://tuchuang-1258543525.cos.ap-beijing.myqcloud.com/20180614_161325021_iOS.jpg" rel="Shortcut Icon" type="image/x-icon">
    <title>Jinhao Jiang (蒋锦昊)</title>

    <link href="./stylesheets/main.css" rel="stylesheet" type="text/css">
    <style id="dark-reader-style" type="text/css">
        @media screen {
            /* Leading rule */
            /*html {
  -webkit-filter: brightness(100%) contrast(100%) grayscale(20%) sepia(10%) !important;
}*/
            /* Text contrast */
            html {
                text-shadow: 0 0 0 !important;
            }
            /* Full screen */
            *:-webkit-full-screen,
            *:-webkit-full-screen * {
                -webkit-filter: none !important;
            }
            /* Page background */
            html {
                background: rgb(255, 255, 255) !important;
            }
        }
    </style>

    <script type="text/javascript">
        function visibility_on(id) {
            var e = document.getElementById(id + "_text");
            if (e.style.display == 'none')
                e.style.display = 'block';
            var e = document.getElementById(id + "_img");
            if (e.style.display == 'none')
                e.style.display = 'block';
        }

        function visibility_off(id) {
            var e = document.getElementById(id + "_text");
            if (e.style.display == 'block')
                e.style.display = 'none';
            var e = document.getElementById(id + "_img");
            if (e.style.display == 'block')
                e.style.display = 'none';
        }

        function toggle_visibility(id) {
            var e = document.getElementById(id + "_text");
            if (e.style.display == 'inline')
                e.style.display = 'block';
            else
                e.style.display = 'inline';
            var e = document.getElementById(id + "_img");
            if (e.style.display == 'inline')
                e.style.display = 'block';
            else
                e.style.display = 'inline';
        }

        function toggle_vis(id) {
            var e = document.getElementById(id);
            if (e.style.display == 'none')
                e.style.display = 'inline';
            else
                e.style.display = 'none';
        }
    </script>

</head>
</div>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
        <tr>
            <td>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                        <tr>
                            <td width="67%" valign="middle">
                                <p align="center">
                                    <name>Jinhao Jiang (蒋锦昊)</name><br>
                                </p>
                                <p style="text-align:justify">
                                    I am a fourth-year Ph.D. student supervised by <a href="http://playbigdata.ruc.edu.cn/batmanfly/">Prof. Xin Zhao</a> from <a href="http://ai.ruc.edu.cn/english/index.htm">GSAI</a>,
                                    <a href="https://ruc.edu.cn">Renmin University of China</a>. I have a broad interest in natural language processing and large language model, with an emphasis on <strong>knowledge augmentation</strong> and <strong>complex reasoning</strong>, especially for complex data (e.g., Knowledge Graph, Database), complex search (e.g., RAG, AI Searcher), and complex reasoning (e.g., Math).
                                </p>
                                <p>Email: jiangjinhao at ruc dot edu dot cn</p>

                                <p align="center">
                                    <a href="./images/resume_cn.pdf" target="_blank">CV_CN</a> &nbsp;/&nbsp;
                                    <a href="./images/resume.pdf" target="_blank">CV_EN</a> &nbsp;/&nbsp;
                                    <a href="https://scholar.google.com/citations?user=TeFKijMAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
                                    <a href="https://github.com/JBoRu" target="_blank"> GitHub </a> &nbsp;/&nbsp;
                                    <a href="https://www.zhihu.com/people/heng-zu-hao" target="_blank">Zhihu</a>
                                </p>
                            </td>
                            <td width="33%">
                                <img src="./images/jiangjinhao.jpg" width="80%">
                            </td>
                        </tr>
                    </tbody>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Education</heading> <br><br>
                                <ul>
                                    <li>Ph.D. student of Artificial Intelligence, Renmin University of China, 2021-2026 (Expected)
                                    </li>
                                    <li>B.Sc. of Computer Science, University of Electronic Science and Technology of China, 2017-2021
                                    </li>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Experience</heading> <br><br>
                                <ul>
                                    <li>2025/01 - present: ByteDance (字节跳动) LLM Research Intern
                                    </li>
                                    <li>2024/10 - 2024/12: BAAI (智源研究院) LLM Research Intern
                                    </li>
                                    <li>2023/07 - 2024/10: Boss Zhipin (BOSS直聘) LLM Research Intern
                                    </li>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Selected Publications</heading> <br><br>

                                Here, I've listed my work as a (co-) first author. For the complete list of my publications, please visit my <a href="https://scholar.google.com/citations?user=TeFKijMAAAAJ&hl=en">Google Scholar</a> profile.<br><br>
                                
                                <!-- <heading2><i>Preprint</i></heading2><br><br> -->

                                <!-- <div onmouseover="document.getElementById('LLM-Survey').style.display = 'block';" onmouseout="document.getElementById('LLM-Survey').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2303.18223.pdf">
                                        <papertitle>A Survey of Large Language Models
                                        </papertitle>
                                    </a><br>
                                    <i>Wayne Xin Zhao</i>,
                                    <i>Kun Zhou</i>&dagger;,
                                    <i>Junyi Li</i>&dagger;,
                                    <i>Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, <strong>Jinhao Jiang</strong>, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu</i>,
                                    <i>Jian-Yun Nie</i>,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>arXiv</em>, 2023 <br>
                                    <a href="https://arxiv.org/pdf/2303.18223.pdf">pdf</a> / <a href="https://github.com/RUCAIBox/LLMSurvey">code</a>
                                </div>
                                <div id="LLM-Survey" style="display:none;text-align:justify">
                                    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling
                                    has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been
                                    proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they
                                    further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance
                                    improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models
                                    (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention
                                    from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent
                                    advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation.
                                    Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.
                                </div><br> -->

                                <div onmouseover="document.getElementById('STILL-2').style.display = 'block';" onmouseout="document.getElementById('STILL-2').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2412.09413?.pdf">
                                        <!-- <font color="#FF0000">!!!!!</font> -->
                                        <papertitle>Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems
                                        </papertitle>
                                    </a><br>
                                    <i>Yingqian Min</i>&dagger;,
                                    <i>Zhipeng Chen</i>&dagger;,
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Jie Chen</i>,
                                    <i>Jia Deng</i>,
                                    <i>Yiwen Hu</i>,
                                    <i>Yiru Tang</i>,
                                    <i>Jiapeng Wang</i>,
                                    <i>Xiaoxue Cheng</i>,
                                    <i>Huatong Song</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Zheng Liu</i>,
                                    <i>Zhongyuan Wang</i>,
                                    <i>Ji-Rong Wen</i>,
                                    <br>
                                    <em>Technical Report</em>, 2024 <br>
                                    <a href="https://arxiv.org/pdf/2412.09413?.pdf">pdf</a>
                                </div>
                                <div id="STILL-2" style="display:none;text-align:justify">
                                    Recently, slow-thinking reasoning systems, such as o1, have demonstrated remarkable capabilities in solving complex reasoning tasks. These systems typically engage in an extended thinking process before responding to a query, allowing them to generate more thorough, accurate, and well-reasoned solutions. These systems are primarily developed and maintained by industry, with their core techniques not publicly disclosed. In response, an increasing number of studies from the research community aim to explore the technical foundations underlying these powerful reasoning systems. Building on these prior efforts, this paper presents a reproduction report on implementing o1-like reasoning systems. We introduce an "imitate, explore, and self-improve" framework as our primary technical approach to train the reasoning model. In the initial phase, we use distilled long-form thought data to fine-tune the reasoning model, enabling it to invoke a slow-thinking mode. The model is then encouraged to explore challenging problems by generating multiple rollouts, which can result in increasingly more high-quality trajectories that lead to correct answers. Furthermore, the model undergoes self-improvement by iteratively refining its training dataset. To verify the effectiveness of this approach, we conduct extensive experiments on three challenging benchmarks. The experimental results demonstrate that our approach achieves competitive performance compared to industry-level reasoning systems on these benchmarks.
                                </div><br>
                                
                                <div onmouseover="document.getElementById('STILL-1').style.display = 'block';" onmouseout="document.getElementById('STILL-1').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2411.11694.pdf">
                                        <!-- <font color="#FF0000">!!!!!</font> -->
                                        <papertitle>Enhancing LLM Reasoning with Reward-guided Tree Search
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Zhipeng Chen</i>&dagger;,
                                    <i>Yingqian Min</i>&dagger;,
                                    <i>Jie Chen</i>,
                                    <i>Xiaoxue Cheng</i>,
                                    <i>Jiapeng Wang</i>,
                                    <i>Yiru Tang</i>,
                                    <i>Haoxiang Sun</i>,
                                    <i>Jia Deng</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Zheng Liu</i>,
                                    <i>Dong Yan</i>,
                                    <i>Jian Xie</i>,
                                    <i>Zhongyuan Wang</i>,
                                    <i>Ji-Rong Wen</i>,
                                    <br>
                                    <em>Technical Report</em>, 2024 <br>
                                    <a href="https://arxiv.org/pdf/2411.11694.pdf">pdf</a>
                                </div>
                                <div id="STILL-1" style="display:none;text-align:justify">
                                    Recently, test-time scaling has garnered significant attention from the research community, largely due to the substantial advancements of the o1 model released by OpenAI. By allocating more computational resources during the inference phase, large language models~(LLMs) can extensively explore the solution space by generating more thought tokens or diverse solutions, thereby producing more accurate responses. However, developing an o1-like reasoning approach is challenging, and researchers have been making various attempts to advance this open area of research. In this paper, we present a preliminary exploration into enhancing the reasoning abilities of LLMs through reward-guided tree search algorithms. This framework is implemented by integrating the policy model, reward model, and search algorithm. It is primarily constructed around a tree search algorithm, where the policy model navigates a dynamically expanding tree guided by a specially trained reward model. We thoroughly explore various design considerations necessary for implementing this framework and provide a detailed report of the technical aspects. To assess the effectiveness of our approach, we focus on mathematical reasoning tasks and conduct extensive evaluations on four challenging datasets, significantly enhancing the reasoning abilities of LLMs.
                                </div><br>

                                <div onmouseover="document.getElementById('Mix-CPT').style.display = 'block';" onmouseout="document.getElementById('Mix-CPT').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2412.09413?.pdf">
                                        <!-- <font color="#FF0000">!!!!!</font> -->
                                        <papertitle>Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Junyi Li</i>&dagger;,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Yang Song</i>,
                                    <i>Tao Zhang</i>,
                                    <i>Ji-Rong Wen</i>,
                                    <br>
                                    <em>ICLR</em>, 2024 <br>
                                    <a href="https://arxiv.org/pdf/2412.09413?.pdf">pdf</a>
                                </div>
                                <div id="Mix-CPT" style="display:none;text-align:justify">
                                    Adapting general large language models (LLMs) to specialized domains presents great challenges due to varied data distributions. This adaptation typically requires continual pre-training on massive domain-specific corpora to facilitate knowledge memorization, followed by training to apply this knowledge following human instructions and preferences. However, this method may result in inefficient knowledge memorization due to a lack of awareness of knowledge utilization and imposes substantial demands on LLMs to simultaneously learn knowledge utilization and format alignment with limited training samples. To facilitate the domain adaptation of LLM, we revise this process and propose a new domain adaptation framework including domain knowledge learning and general format alignment, called Mix-CPT. Specifically, we first conduct a knowledge mixture continual pre-training that concurrently focuses on knowledge memorization and utilization, allowing for mutual reinforcement. To avoid catastrophic forgetting during the continual pre-training process, we further incorporate a logit swap self-distillation constraint. Subsequently, leveraging the knowledge and capabilities acquired during continual pre-training, we efficiently perform instruction tuning and alignment with a few general training samples to achieve format alignment. Extensive experiments demonstrate that our proposed Mix-CPT framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains compared to the traditional adaptation methods.
                                </div><br>

                                <div onmouseover="document.getElementById('RAG-Star').style.display = 'block';" onmouseout="document.getElementById('RAG-Star').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2412.12881.pdf">
                                        <!-- <font color="#FF0000">!!!!!</font> -->
                                        <papertitle>RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Jiayi Chen</i>&dagger;,
                                    <i>Junyi Li</i>&dagger;,
                                    <i>Ruiyang Ren</i>,
                                    <i>Shijie Wang</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Yang Song</i>*,
                                    <i>Tao Zhang</i>,
                                    <br>
                                    <em>NAACL</em>, 2024 <br>
                                    <a href="https://arxiv.org/pdf/2412.12881.pdf">pdf</a>
                                </div>
                                <div id="RAG-Star" style="display:none;text-align:justify">
                                    Existing large language models (LLMs) show exceptional problem-solving capabilities but might struggle with complex reasoning tasks. Despite the successes of chain-of-thought and tree-based search methods, they mainly depend on the internal knowledge of LLMs to search over intermediate reasoning steps, limited to dealing with simple tasks involving fewer reasoning steps. In this paper, we propose \textbf{RAG-Star}, a novel RAG approach that integrates the retrieved information to guide the tree-based deliberative reasoning process that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree Search, RAG-Star iteratively plans intermediate sub-queries and answers for reasoning based on the LLM itself. To consolidate internal and external knowledge, we propose an retrieval-augmented verification that utilizes query- and answer-aware reward modeling to provide feedback for the inherent reasoning of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate that RAG-Star significantly outperforms previous RAG and reasoning methods.
                                </div><br>

                                <div onmouseover="document.getElementById('KGAgent').style.display = 'block';" onmouseout="document.getElementById('KGAgent').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2402.11163.pdf">
                                        <!-- <font color="#FF0000">!!!!!</font> -->
                                        <papertitle>KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>,
                                    <i>Kun Zhou</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Yang Song</i>*,
                                    <i>Chen Zhu</i>,
                                    <i>Hengshu Zhu</i>,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>arXiv</em>, 2024 <br>
                                    <a href="https://arxiv.org/pdf/2402.11163.pdf">pdf</a>
                                </div>
                                <div id="KGAgent" style="display:none;text-align:justify">
                                    In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous
                                    LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs. In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor,
                                    and knowledge memory, and develop an iteration mechanism that autonomously selects the tool then updates the memory for reasoning over KG. To guarantee the effectiveness, we leverage program language to formulate the
                                    multi-hop reasoning process over the KG, and synthesize a code-based instruction dataset to fine-tune the base LLM. Extensive experiments demonstrate that only using 10K samples for tuning LLaMA-7B can outperform state-of-the-art
                                    methods using larger LLMs or more data, on both in-domain and out-domain datasets. Our code and data will be publicly released.
                                </div><br>

                                <!-- <heading2><i>2023</i></heading2><br><br> -->

                                <div onmouseover="document.getElementById('StructGPT').style.display = 'block';" onmouseout="document.getElementById('StructGPT').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2305.09645.pdf">
                                        <papertitle>StructGPT: A General Framework for Large Language Model to Reason over Structured Data
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Kun Zhou</i>&dagger;,
                                    <i>Zican Dong</i>
                                    <i>Keming Ye</i>
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>EMNLP</em>, 2023 <br>
                                    <a href="https://arxiv.org/pdf/2305.09645.pdf">pdf</a> / <a href="https://github.com/RUCAIBox/StructGPT">code</a>
                                </div>
                                <div id="StructGPT" style="display:none;text-align:justify">
                                    In this paper, we study how to improve the zero-shot reasoning ability of large language models (LLMs) over structured data in a unified way. Inspired by the study on tool augmentation for LLMs, we develop an Iterative Reading-then-Reasoning (IRR) approach
                                    for solving question answering tasks based on structured data, called StructGPT. In our approach, we construct the specialized function to collect relevant evidence from structured data (i.e., reading), and let LLMs
                                    concentrate the reasoning task based on the collected information (i.e., reasoning). Specially, we propose an invoking-linearization-generation procedure to support LLMs in reasoning on the structured data with the
                                    help of the external interfaces. By iterating this procedures with provided interfaces, our approach can gradually approach the target answer to a given query. Extensive experiments conducted on three types of structured
                                    data demonstrate the effectiveness of our approach, which can significantly boost the performance of ChatGPT and achieve comparable performance against the full-data supervised-tuning baselines. Our codes and data are
                                    publicly available at https://github.com/RUCAIBox/StructGPT.
                                </div><br>

                                <div onmouseover="document.getElementById('ReasoningLM').style.display = 'block';" onmouseout="document.getElementById('ReasoningLM').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2305.09645.pdf">
                                        <papertitle>ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>,
                                    <i>Kun Zhou</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Yaliang Li</i>,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>EMNLP</em>, 2023 <br>
                                    <a href="https://arxiv.org/pdf/2305.09645.pdf">pdf</a> / <a href="https://github.com/RUCAIBox/ReasoningLM">code</a>
                                </div>
                                <div id="ReasoningLM" style="display:none;text-align:justify">
                                    Question Answering over Knowledge Graph (KGQA) aims to seek answer entities for the natural language question from a large-scale Knowledge Graph~(KG). To better perform reasoning on KG, recent work typically adopts a pre-trained language model~(PLM) to
                                    model the question, and a graph neural network~(GNN) based module to perform multi-hop reasoning on the KG. Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated,
                                    limiting the knowledge sharing and fine-grained feature interactions. To solve it, we aim to simplify the above two-module approach, and develop a more capable PLM that can directly support subgraph reasoning for KGQA,
                                    namely ReasoningLM. In our approach, we propose a subgraph-aware self-attention mechanism to imitate the GNN for performing structured reasoning, and also adopt an adaptation tuning strategy to adapt the model parameters
                                    with 20,000 subgraphs with synthesized questions. After adaptation, the PLM can be parameter-efficient fine-tuned on downstream tasks. Experiments show that ReasoningLM surpasses state-of-the-art models by a large margin,
                                    even with fewer updated parameters and less training data. Our codes and data are publicly available at https://github.com/RUCAIBox/StructGPT.
                                </div><br>

                                <div onmouseover="document.getElementById('UniKGQA').style.display = 'block';" onmouseout="document.getElementById('UniKGQA').style.display='none';">
                                    <a href="https://arxiv.org/abs/2212.00959">
                                        <papertitle>UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph
                                        </papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Kun Zhou</i>&dagger;,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>International Conference on Learning Representations (ICLR)</em>, 2023<br>
                                    <a href="https://arxiv.org/abs/2212.00959">pdf</a> / <a href="https://github.com/RUCAIBox/UniKGQA">code</a>
                                </div>
                                <div id="UniKGQA" style="display:none;text-align:justify">
                                    Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG). To cope with the vast search
                                    space, existing work usually adopts a two-stage approach: it firstly retrieves a relatively small subgraph related to the question and then performs the reasoning on the subgraph to accurately find the answer entities.
                                    Although these two stages are highly related, previous work employs very different technical solutions for developing the retrieval and reasoning models, neglecting their relatedness in task essence. In this paper,
                                    we propose UniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and reasoning in both model architecture and parameter learning. For model architecture, UniKGQA consists of a semantic matching module
                                    based on a pre-trained language model~(PLM) for question-relation semantic matching, and a matching information propagation module to propagate the matching information along the edges on KGs. For parameter learning,
                                    we design a shared pre-training task based on question-relation matching for both retrieval and reasoning models, and then propose retrieval- and reasoning-oriented fine-tuning strategies. Compared with previous studies,
                                    our approach is more unified, tightly relating the retrieval and reasoning stages. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our method on the multi-hop KGQA task. Our
                                    codes and data are publicly available at https://github.com/RUCAIBox/UniKGQA.
                                </div><br>

                                <!-- <heading2><i>2022</i></heading2><br><br> -->

                                <div onmouseover="document.getElementById('SAFE').style.display = 'block';" onmouseout="document.getElementById('SAFE').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2205.01841.pdf">
                                        <papertitle>Great Truths are Always Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models</papertitle>
                                    </a><br>
                                    <i><strong>Jinhao Jiang</strong></i>&dagger;,
                                    <i>Kun Zhou</i>&dagger;,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>The North American Chapter of the Association for Computational Linguistics (NAACL-Findings)</em>, 2022<br>
                                    <a href="https://arxiv.org/pdf/2205.01841.pdf">pdf</a> / <a href="https://github.com/RUCAIBox/SAFE">code</a>
                                </div>
                                <div id="SAFE" style="display:none;text-align:justify">
                                    Commonsense reasoning in natural language is a desired ability of artificial intelligent systems. For solving complex commonsense reasoning tasks, a typical solution is to enhance pre-trained language models~(PTMs) with a knowledge-aware graph neural
                                    network~(GNN) encoder that models a commonsense knowledge graph~(CSKG). Despite the effectiveness, these approaches are built on heavy architectures, and can't clearly explain how external knowledge resources improve
                                    the reasoning capacity of PTMs. Considering this issue, we conduct a deep empirical analysis, and find that it is indeed relation features from CSKGs (but not node features) that mainly contribute to the performance
                                    improvement of PTMs. Based on this finding, we design a simple MLP-based knowledge encoder that utilizes statistical relation paths as features. Extensive experiments conducted on five benchmarks demonstrate the effectiveness
                                    of our approach, which also largely reduces the parameters for encoding CSKGs. Our codes and data are publicly available at https://github.com/RUCAIBox/SAFE.
                                </div><br>

                                <div onmouseover="document.getElementById('KBQA-Survey-TKDE').style.display = 'block';" onmouseout="document.getElementById('KBQA-Survey-TKDE').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2108.06688.pdf">
                                        <papertitle>Complex Knowledge Base Question Answering: A Survey
                                        </papertitle>
                                    </a><br>
                                    <i>Yunshi Lan</i>&dagger;,
                                    <i>Gaole He</i>&dagger;,
                                    <i><strong>Jinhao Jiang</strong></i>,
                                    <i>Jing Jiang</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>IEEE Transactions on Knowledge and Data Engineering (TKDE)</em>, 2022 <br>
                                    <a href="https://arxiv.org/pdf/2108.06688.pdf">pdf</a>
                                </div>
                                <div id="KBQA-Survey-TKDE" style="display:none;text-align:justify">
                                    Knowledge base question answering (KBQA) aims to answer a question over a knowledge base (KB). Early studies mainly focused on answering simple questions over KBs and achieved great success. However, their performance on complex questions is still far
                                    from satisfactory. Therefore, in recent years, researchers propose a large number of novel methods, which looked into the challenges of answering complex questions. In this survey, we review recent advances on KBQA
                                    with the focus on solving complex questions, which usually contain multiple subjects, express compound relations, or involve numerical operations. In detail, we begin with introducing the complex KBQA task and relevant
                                    background. Then, we describe benchmark datasets for complex KBQA task and introduce the construction process of these datasets. Next, we present two mainstream categories of methods for complex KBQA, namely semantic
                                    parsing-based (SP-based) methods and information retrieval-based (IR-based) methods. Specifically, we illustrate their procedures with flow designs and discuss their major differences and similarities. After that, we
                                    summarize the challenges that these two categories of methods encounter when answering complex questions, and explicate advanced solutions and techniques used in existing work. Finally, we conclude and discuss several
                                    promising directions related to complex KBQA for future research.
                                </div><br>

                                <!-- <heading2><i>2021</i></heading2><br><br>

                                <div onmouseover="document.getElementById('TextBox').style.display = 'block';" onmouseout="document.getElementById('TextBox').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2101.02046.pdf">
                                        <papertitle>TextBox: A Unified, Modularized, and Extensible Framework for Text Generation</papertitle>
                                    </a><br>
                                    <i>Junyi Li</i>&dagger;,
                                    <i>Tianyi Tang</i>&dagger;,
                                    <i>Gaole He</i>,
                                    <i><strong>Jinhao Jiang</strong></i>,
                                    <i>Xiaoxuan Hu</i>,
                                    <i>Puzhao Xie</i>,
                                    <i>Zhipeng Chen</i>,
                                    <i>Zhuohao Yu</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>The 59th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2021, System Demonstration <br>
                                    <a href="https://arxiv.org/pdf/2101.02046.pdf">pdf</a> / <a href="https://github.com/RUCAIBox/TextBox">code</a>
                                </div>
                                <div id="TextBox" style="display:none;text-align:justify">
                                    We release an open library, called TextBox, which provides a unified, modularized, and extensible text generation framework. TextBox aims to support a broad set of text generation tasks and models. In TextBox, we implements several text generation models
                                    on benchmark datasets, covering the categories of VAE, GAN, pre-trained language models, etc. Meanwhile, our library maintains sufficient modularity and extensibility by properly decomposing the model architecture,
                                    inference, learning process into highly reusable modules, which allows easily incorporating new models into our framework. It is specially suitable for researchers and practitioners to efficiently reproduce baseline
                                    models and develop new models. TextBox is implemented based on PyTorch, and released under Apache License 2.0 at the link https://github.com/RUCAIBox/TextBox.
                                </div><br> -->

                                <!-- <div onmouseover="document.getElementById('KBQA-Survey-IJCAI').style.display = 'block';" onmouseout="document.getElementById('KBQA-Survey-IJCAI').style.display='none';">
                                    <a href="https://arxiv.org/pdf/2105.11644.pdf">
                                        <papertitle>A survey on complex knowledge base question answering: Methods, challenges and solutions</papertitle>
                                    </a><br>
                                    <i>Yunshi Lan</i>&dagger;,
                                    <i>Gaole He</i>&dagger;,
                                    <i><strong>Jinhao Jiang</strong></i>,
                                    <i>Jing Jiang</i>,
                                    <i>Wayne Xin Zhao</i>*,
                                    <i>Ji-Rong Wen</i>
                                    <br>
                                    <em>The 30th International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2021, Survey Track <br>
                                    <a href="https://arxiv.org/pdf/2105.11644.pdf">pdf</a>
                                </div>
                                <div id="KBQA-Survey-IJCAI" style="display:none;text-align:justify">
                                    Knowledge base question answering (KBQA) aims to answer a question over a knowledge base (KB). Recently, a large number of studies focus on semantically or syntactically complicated questions. In this paper, we elaborately summarize the typical challenges
                                    and solutions for complex KBQA. We begin with introducing the background about the KBQA task. Next, we present the two mainstream categories of methods for complex KBQA, namely semantic parsing-based (SP-based) methods
                                    and information retrieval-based (IR-based) methods. We then review the advanced methods comprehensively from the perspective of the two categories. Specifically, we explicate their solutions to the typical challenges.
                                    Finally, we conclude and discuss some promising directions for future research.
                                </div><br> * Corresponding author <br> &dagger; Equal contribution -->
                            </td>
                        </tr>

                        <tr>
                            <td>
                                <heading>Zhihu Posts</heading>
                                <ul>
                                    <li> <a href="https://zhuanlan.zhihu.com/p/501680110" target="_blank">ACL 2022 主会长文论文分类整理</a></li>
                                    <li> <a href="https://zhuanlan.zhihu.com/p/409061361" target="_blank">可能是目前最全面的知识库复杂问答综述解读</a></li>
                                    <li> <a href="https://zhuanlan.zhihu.com/p/384952066" target="_blank">基于知识图谱的问答系统相关论文分类整理</a></li>

                                    <li> <a href="javascript:toggle_vis('zhihu-blogs')" style="color:black">show more</a> </li>
                                    <div id="zhihu-blogs" style="display:none">
                                        <li> <a href="https://zhuanlan.zhihu.com/p/354274764" target="_blank">GAN理论推导</a></li>
                                    </div>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Open Source Projects</heading> <br><br> (Most of my research work are open-source. Here are some my preferable projects!)
                                <ul>
                                    <li><a href="https://github.com/RUCAIBox/Slow_Thinking_with_LLMs" target="_black">O1 Reproduction</a><br>STILL: Slow Thinking with LLMs.</li>
                                </ul>
                                <ul>
                                    <li><a href="https://github.com/RUCAIBox/TextBox" target="_black">TextBox</a><br>A unified, comprehensive and efficient framework for reproducing and developing text generation algorithms, covering more than 20 base models
                                        and nearly 10 benchmarks.</li>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Professional Services</heading> <br><br>
                                <ul>
                                    <li>Reviewer
                                        <ul>
                                            <li>Journal: TALLIP, Computational Intelligence, Information Retrieval Journa</li>
                                            <li>Conference: ICLR, NIPS, ACL, EMNLP</li>
                                        </ul>
                                    </li>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <heading>Selected Awards and Honors</heading> <br><br>
                                <ul>
                                    <li>2021 Outstanding Graduates of Sichuan Province (winning ratio 3.7%), Education Department of Sichuan.</li>
                                    <li>2020 China National Scholarship (top 1.5%), Ministry of Education of the People's Republic of China.</li>
                                    <li>2019 China National Scholarship (top 1.5%), Ministry of Education of the People's Republic of China.</li>
                                    <li>2019 Meritorious Winner (winning ratio 7.09%) in Mathematical Contest In Modeling, the COMAP of American.</li>
                                </ul>
                            </td>
                        </tr>

                        <tr>
                            <td width="100%" valign="middle">
                                <center>
                                    <script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=571ds4qroi6&amp;s=220&amp;m=7&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
                                </center>
                            </td>
                        </tr>

                    </tbody>
                </table>


                <script>
                    (function(i, s, o, g, r, a, m) {
                        i['GoogleAnalyticsObject'] = r;
                        i[r] = i[r] || function() {
                            (i[r].q = i[r].q || []).push(arguments)
                        }, i[r].l = 1 * new Date();
                        a = s.createElement(o),
                            m = s.getElementsByTagName(o)[0];
                        a.async = 1;
                        a.src = g;
                        m.parentNode.insertBefore(a, m)
                    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

                    ga('create', 'UA-59618557-1', 'auto');
                    ga('send', 'pageview');
                </script>

            </td>
        </tr>
    </tbody>
</table>

<!--footer start-->
<footer class="footer">
    <p>Copyright 2021. All Rights Reserved by Jinhao Jiang.</p>
</footer>
<!--footer end-->

</body>

</html>
